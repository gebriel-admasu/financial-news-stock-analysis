{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the news dataset\n",
    "news_data = pd.read_csv(\"../data/raw_analyst_ratings.csv\")\n",
    "print(news_data.head())\n",
    "print(news_data.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze headline length\n",
    "news_data['headline_length'] = news_data['headline'].str.len()\n",
    "sns.histplot(news_data['headline_length'], bins=30, kde=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores\n",
    "news_data['sentiment'] = news_data['headline'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Categorize sentiment as positive, neutral, or negative\n",
    "news_data['sentiment_category'] = news_data['sentiment'].apply(\n",
    "    lambda score: 'positive' if score > 0.05 else ('negative' if score < -0.05 else 'neutral')\n",
    ")\n",
    "\n",
    "# Display sentiment distribution\n",
    "print(news_data['sentiment_category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(data=news_data, x='sentiment_category', palette='viridis')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Headlines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Extract Common Keywords or Phrases\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=20)\n",
    "\n",
    "# Fit and transform headlines\n",
    "tfidf_matrix = tfidf.fit_transform(news_data['headline'])\n",
    "top_keywords = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"Top Keywords:\", top_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Initialize LDA model\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)  # 5 topics\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "# Display top words for each topic\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {idx + 1}:\")\n",
    "    print([tfidf.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result \n",
    "news_data.to_csv(\"../data/processed_sentiment_topic_modeling.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic modeling\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "yfinance_data_dir = '../data/yfinance_data/'\n",
    "csv_files = [f for f in os.listdir(yfinance_data_dir) if f.endswith('.csv')]\n",
    "stock_data = {file: pd.read_csv(os.path.join(yfinance_data_dir, file)) for file in csv_files}\n",
    "print(stock_data['AAPL_historical_data.csv'].head())  # Checking the data for AAPL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['date'] = pd.to_datetime(news_data['date'], errors='coerce')\n",
    "print(news_data['date'].isnull().sum())  # Check for invalid entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_data['date'].dtypes)\n",
    "print(news_data['date'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['publication_date'] = news_data['date'].dt.date\n",
    "daily_publication_counts = news_data['publication_date'].value_counts().sort_index()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(dpi= 200, figsize=(12, 6))\n",
    "daily_publication_counts.plot(kind='line', title=\"Daily Publication Trends\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_counts = news_data['publisher'].value_counts()\n",
    "print(publisher_counts.head(10))  # Display the top 10 publishers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "top_publishers = publisher_counts.head(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_publishers.index, y=top_publishers.values, palette=\"viridis\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 Publishers by Article Count\")\n",
    "plt.xlabel(\"Publisher\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for publisher in top_publishers.index:\n",
    "    print(f\"\\nHeadlines for {publisher}:\")\n",
    "    print(news_data[news_data['publisher'] == publisher]['headline'].head(5))  # Show 5 sample headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Analyze content for a specific publisher\n",
    "selected_publisher = top_publishers.index[0]  # Example: the most frequent publisher\n",
    "publisher_headlines = news_data[news_data['publisher'] == selected_publisher]['headline']\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=20)\n",
    "tfidf_matrix = tfidf.fit_transform(publisher_headlines)\n",
    "print(f\"Top Keywords for {selected_publisher}: {tfidf.get_feature_names_out()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['publisher_domain'] = news_data['publisher'].apply(\n",
    "    lambda x: x.split('@')[-1] if '@' in x else None\n",
    ")\n",
    "domain_counts = news_data['publisher_domain'].value_counts()\n",
    "print(domain_counts.head(10))  # Display the top 10 domains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_domains = domain_counts.head(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_domains.index, y=top_domains.values, palette=\"coolwarm\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 10 Email Domains by Article Count\")\n",
    "plt.xlabel(\"Domain\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
